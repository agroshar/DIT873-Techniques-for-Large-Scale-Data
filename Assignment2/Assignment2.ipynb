{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\qquad$ $\\qquad$$\\qquad$  **DAT346/DIT873 Techniques for Large-Scale Data** <br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$ **Assignment 2**<br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$                   **Submitted by: group 23** <br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$$\\qquad$     **Julia Szulc, 961029-7245, juliasz@student.chalmers.se** <br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$$\\qquad$     **Ahmed Groshar, 961222-1912, gusgroah@student.gu.se** <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) This section describes a higher pseudo-code view of the k-means implementation we try to parallelize:\n",
    "    \n",
    "    def nearestCentroid(datum, centroids):\n",
    "        # function computing distance from data point to centroids\n",
    "        \n",
    "    def evaluate_results(clustering_results, k):\n",
    "        # combine new centroid values for each centroid\n",
    "\n",
    "    \n",
    "    def workerTask(worker_data):\n",
    "    \n",
    "        # compute nearest centroid to each chunk dataset\n",
    "        # compute partial new centriod \n",
    "        for i in range(N_data_points_chunk):\n",
    "                cluster, dist = nearestCentroid(data[i],centroids)\n",
    "                ...\n",
    "                new_centroids[cluster] += data_chunk[i]\n",
    "        \n",
    "\n",
    "    def kmeans(k, data, nr_iter = 100):\n",
    "    \n",
    "        # for a given number of iterations\n",
    "        for j in range(nr_iter):\n",
    "        \n",
    "            # Give each worker a chunk dataset and centroids\n",
    "            processes = mp.Pool(workers)\n",
    "            clustering_results = processes.map(workerTask, workers_data)\n",
    "\n",
    "            # combine centroid values from workers\n",
    "            evaluate_results(clustering_results, k)\n",
    "            \n",
    "          \n",
    "            \n",
    "The first two function _nearestCentroid()_ and _evaluate_results()_ are helper functions that are called to compute the nearest centroid for a point and the second function to combine the results for the reassignment of new centroids. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
